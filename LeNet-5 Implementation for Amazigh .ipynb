{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdc1f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy==1.22.4 scipy==1.10.1 umap-learn scikit-learn tqdm matplotlib seaborn opencv-python-headless torch torchvision torchaudio --upgrade --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395c3af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install umap-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00cdc77",
   "metadata": {},
   "source": [
    "### LeNet-5 Implementation for Amazigh Handwritten Character Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ad7ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"LeNet-5 Implementation for AMHCD Classification\n",
    "\n",
    "This script implements LeNet-5 architecture for classifying Amazigh handwritten characters (33 classes).\n",
    "It includes data preprocessing, model training, evaluation, and visualization.\n",
    "\n",
    "Requirements:\n",
    "- Python 3.7+\n",
    "- PyTorch 1.9+\n",
    "- torchvision\n",
    "- scikit-learn\n",
    "- matplotlib\n",
    "- seaborn\n",
    "- numpy\n",
    "- pandas\n",
    "- umap-learn\n",
    "- opencv-python\n",
    "\n",
    "Example:\n",
    "    $ python lenet5_amhcd.py\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Section 1: Imports & Environment Setup\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import umap\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('figures', exist_ok=True)\n",
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Section 2: Dataset Loading & Preprocessing\n",
    "class AMHCDDataset(Dataset):\n",
    "    \"\"\"AMHCD Dataset class for loading and preprocessing Amazigh handwritten characters.\"\"\"\n",
    "    \n",
    "    def __init__(self, root_dir, transform=None, split='train', mean=None, std=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.split = split\n",
    "        self.classes = sorted(os.listdir(root_dir))\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Load images and labels\n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            if os.path.isdir(class_dir):\n",
    "                for img_name in os.listdir(class_dir):\n",
    "                    if img_name.endswith('.png'):\n",
    "                        self.images.append(os.path.join(class_dir, img_name))\n",
    "                        self.labels.append(self.class_to_idx[class_name])\n",
    "        \n",
    "        # Calculate mean and std from training set if not provided\n",
    "        if mean is None or std is None:\n",
    "            self.mean, self.std = self.calculate_mean_std()\n",
    "        else:\n",
    "            self.mean, self.std = mean, std\n",
    "            \n",
    "        # Update transform with normalization\n",
    "        if self.transform is None:\n",
    "            self.transform = self.get_default_transform()\n",
    "        else:\n",
    "            # Add normalization to the provided transform\n",
    "            self.transform.transforms.append(transforms.Normalize(self.mean, self.std))\n",
    "    \n",
    "    def calculate_mean_std(self):\n",
    "        \"\"\"Calculate mean and standard deviation of the training set.\"\"\"\n",
    "        print(\"Calculating mean and std from training data...\")\n",
    "        mean = np.zeros(3)\n",
    "        std = np.zeros(3)\n",
    "        num_pixels = 0\n",
    "        \n",
    "        for img_path in self.images:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img = np.array(img) / 255.0\n",
    "            mean += img.mean(axis=(0, 1))\n",
    "            std += img.std(axis=(0, 1))\n",
    "            num_pixels += 1\n",
    "        \n",
    "        mean /= num_pixels\n",
    "        std /= num_pixels\n",
    "        \n",
    "        return mean, std\n",
    "    \n",
    "    def get_default_transform(self):\n",
    "        \"\"\"Get default transform based on split (train/val/test).\"\"\"\n",
    "        if self.split == 'train':\n",
    "            return transforms.Compose([\n",
    "                transforms.Resize((32, 32)),\n",
    "                transforms.RandomRotation(10),\n",
    "                transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
    "                transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(self.mean, self.std)\n",
    "            ])\n",
    "        else:\n",
    "            return transforms.Compose([\n",
    "                transforms.Resize((32, 32)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(self.mean, self.std)\n",
    "            ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Load dataset and create splits\n",
    "dataset_path = \"data/amhcd\"\n",
    "full_dataset = AMHCDDataset(dataset_path, split='train')\n",
    "\n",
    "# Get mean and std from full dataset for consistent normalization\n",
    "mean, std = full_dataset.mean, full_dataset.std\n",
    "\n",
    "# Split dataset into train, val, test (70/15/15)\n",
    "train_idx, temp_idx = train_test_split(\n",
    "    range(len(full_dataset)), \n",
    "    test_size=0.3, \n",
    "    random_state=seed, \n",
    "    stratify=full_dataset.labels\n",
    ")\n",
    "val_idx, test_idx = train_test_split(\n",
    "    temp_idx, \n",
    "    test_size=0.5, \n",
    "    random_state=seed, \n",
    "    stratify=[full_dataset.labels[i] for i in temp_idx]\n",
    ")\n",
    "\n",
    "# Create subset datasets\n",
    "train_dataset = torch.utils.data.Subset(full_dataset, train_idx)\n",
    "val_dataset = torch.utils.data.Subset(full_dataset, val_idx)\n",
    "test_dataset = torch.utils.data.Subset(full_dataset, test_idx)\n",
    "\n",
    "# Set the split type for each subset\n",
    "train_dataset.dataset.split = 'train'\n",
    "val_dataset.dataset.split = 'val'\n",
    "test_dataset.dataset.split = 'test'\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Section 3: DataLoaders\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Section 4: LeNet-5 Model Definition\n",
    "class LeNet5(nn.Module):\n",
    "    \"\"\"LeNet-5 architecture adapted for 33-class AMHCD classification.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=33, dropout_rate=0.2):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        # Feature extraction layers\n",
    "        self.features = nn.Sequential(\n",
    "            # Conv1: input 32x32x3, output 28x28x6\n",
    "            nn.Conv2d(3, 6, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            # Pool1: output 14x14x6\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Conv2: output 10x10x16\n",
    "            nn.Conv2d(6, 16, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            # Pool2: output 5x5x16\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            # Conv3: output 1x1x120\n",
    "            nn.Conv2d(16, 120, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # Classifier layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout_rate),\n",
    "            nn.Linear(84, num_classes),\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights using Kaiming He initialization for ReLU activations.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Create model\n",
    "model = LeNet5(num_classes=33, dropout_rate=0.2).to(device)\n",
    "print(model)\n",
    "\n",
    "# Section 5: Training Function + Validation\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# Initialize metrics tracking\n",
    "train_losses, val_losses = [], []\n",
    "train_accs, val_accs = [], []\n",
    "best_val_acc = 0.0\n",
    "\n",
    "def train_epoch(model, loader, optimizer, criterion, device):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate_epoch(model, loader, criterion, device):\n",
    "    \"\"\"Validate for one epoch.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# Training loop\n",
    "print(\"Starting training...\")\n",
    "for epoch in range(30):\n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Save metrics\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'models/best.pt')\n",
    "    \n",
    "    print(f'Epoch {epoch+1:02d}: '\n",
    "          f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "\n",
    "# Save final model\n",
    "torch.save(model.state_dict(), 'models/final.pt')\n",
    "\n",
    "# Save metrics to CSV\n",
    "metrics_df = pd.DataFrame({\n",
    "    'epoch': range(1, 31),\n",
    "    'train_loss': train_losses,\n",
    "    'val_loss': val_losses,\n",
    "    'train_acc': train_accs,\n",
    "    'val_acc': val_accs\n",
    "})\n",
    "metrics_df.to_csv('results/metrics.csv', index=False)\n",
    "\n",
    "# Section 6: Evaluation on Test Set\n",
    "print(\"Evaluating on test set...\")\n",
    "model.load_state_dict(torch.load('models/best.pt'))\n",
    "test_loss, test_acc = validate_epoch(model, test_loader, criterion, device)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%')\n",
    "\n",
    "# Get predictions for test set\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "all_probs = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        probs = torch.softmax(output, dim=1)\n",
    "        \n",
    "        _, preds = output.max(1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_targets.extend(target.cpu().numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "# Calculate F1 scores\n",
    "macro_f1 = f1_score(all_targets, all_preds, average='macro')\n",
    "weighted_f1 = f1_score(all_targets, all_preds, average='weighted')\n",
    "\n",
    "print(f'Test Accuracy: {test_acc:.2f}%')\n",
    "print(f'Macro F1: {macro_f1:.3f}')\n",
    "print(f'Weighted F1: {weighted_f1:.3f}')\n",
    "\n",
    "# Generate classification report\n",
    "class_report = classification_report(all_targets, all_preds, target_names=full_dataset.classes, output_dict=True)\n",
    "class_report_df = pd.DataFrame(class_report).transpose()\n",
    "class_report_df.to_csv('results/classification_report.csv')\n",
    "\n",
    "# Section 7: Generate Figures\n",
    "\n",
    "# 7.1 Loss & Accuracy curves\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accs, label='Train Accuracy')\n",
    "plt.plot(val_accs, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/loss_acc.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 7.2 Confusion matrix\n",
    "plt.figure(figsize=(15, 12))\n",
    "cm = confusion_matrix(all_targets, all_preds)\n",
    "sns.heatmap(cm, annot=False, fmt='d', cmap='Blues', \n",
    "            xticklabels=full_dataset.classes, \n",
    "            yticklabels=full_dataset.classes)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 7.3 Grid of sample predictions\n",
    "def visualize_predictions(model, loader, class_names, device, num_samples=12):\n",
    "    \"\"\"Visualize sample predictions.\"\"\"\n",
    "    model.eval()\n",
    "    images, labels = next(iter(loader))\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(images[:num_samples])\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        pred_probs, preds = probs.max(1)\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 4, figsize=(15, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Denormalize image\n",
    "        img = images[i].cpu().numpy().transpose((1, 2, 0))\n",
    "        img = img * std + mean  # Reverse normalization\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f'True: {class_names[labels[i]]}\\n'\n",
    "                         f'Pred: {class_names[preds[i]]}\\n'\n",
    "                         f'Prob: {pred_probs[i]:.3f}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('figures/samples_grid.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "visualize_predictions(model, test_loader, full_dataset.classes, device)\n",
    "\n",
    "# 7.4 t-SNE visualization of features\n",
    "def extract_features(model, loader, device):\n",
    "    \"\"\"Extract features from the model.\"\"\"\n",
    "    model.eval()\n",
    "    features = []\n",
    "    targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data = data.to(device)\n",
    "            # Extract features from the layer before the classifier\n",
    "            feature = model.features(data)\n",
    "            feature = torch.flatten(feature, 1)\n",
    "            features.append(feature.cpu().numpy())\n",
    "            targets.append(target.numpy())\n",
    "    \n",
    "    return np.vstack(features), np.concatenate(targets)\n",
    "\n",
    "print(\"Extracting features for t-SNE visualization...\")\n",
    "features, targets = extract_features(model, test_loader, device)\n",
    "\n",
    "# Apply UMAP (better for visualization than t-SNE in many cases)\n",
    "reducer = umap.UMAP(random_state=seed)\n",
    "embedding = reducer.fit_transform(features)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "scatter = plt.scatter(embedding[:, 0], embedding[:, 1], c=targets, cmap='tab20', s=10)\n",
    "plt.colorbar(scatter, ticks=range(33))\n",
    "plt.title('UMAP Visualization of Feature Space')\n",
    "plt.savefig('figures/umap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# 7.5 Grad-CAM visualization\n",
    "class GradCAM:\n",
    "    \"\"\"Grad-CAM implementation for visualization.\"\"\"\n",
    "    \n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        self.hooks = []\n",
    "        \n",
    "        # Register hooks\n",
    "        self._register_hooks()\n",
    "    \n",
    "    def _register_hooks(self):\n",
    "        def forward_hook(module, input, output):\n",
    "            self.activations = output\n",
    "        \n",
    "        def backward_hook(module, grad_input, grad_output):\n",
    "            self.gradients = grad_output[0]\n",
    "        \n",
    "        self.hooks.append(self.target_layer.register_forward_hook(forward_hook))\n",
    "        self.hooks.append(self.target_layer.register_backward_hook(backward_hook))\n",
    "    \n",
    "    def generate(self, input_image, target_class=None):\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = self.model(input_image.unsqueeze(0))\n",
    "        \n",
    "        if target_class is None:\n",
    "            target_class = output.argmax(dim=1).item()\n",
    "        \n",
    "        # Backward pass\n",
    "        self.model.zero_grad()\n",
    "        one_hot = torch.zeros_like(output)\n",
    "        one_hot[0, target_class] = 1\n",
    "        output.backward(gradient=one_hot)\n",
    "        \n",
    "        # Calculate weights\n",
    "        gradients = self.gradients[0].cpu().numpy()\n",
    "        activations = self.activations[0].cpu().numpy()\n",
    "        weights = np.mean(gradients, axis=(1, 2))\n",
    "        \n",
    "        # Generate CAM\n",
    "        cam = np.zeros(activations.shape[1:], dtype=np.float32)\n",
    "        for i, w in enumerate(weights):\n",
    "            cam += w * activations[i]\n",
    "        \n",
    "        cam = np.maximum(cam, 0)  # ReLU\n",
    "        cam = cv2.resize(cam, (32, 32))\n",
    "        cam = cam - np.min(cam)\n",
    "        cam = cam / np.max(cam) if np.max(cam) > 0 else cam\n",
    "        \n",
    "        return cam, target_class\n",
    "    \n",
    "    def remove_hooks(self):\n",
    "        for hook in self.hooks:\n",
    "            hook.remove()\n",
    "\n",
    "# Apply Grad-CAM to sample images\n",
    "def apply_gradcam(model, loader, device, num_images=6):\n",
    "    \"\"\"Apply Grad-CAM to sample images.\"\"\"\n",
    "    # Get target layer (last convolutional layer)\n",
    "    target_layer = model.features[-2]  # The last conv layer before ReLU\n",
    "    \n",
    "    # Initialize Grad-CAM\n",
    "    gradcam = GradCAM(model, target_layer)\n",
    "    \n",
    "    # Get sample images (3 correct, 3 incorrect)\n",
    "    model.eval()\n",
    "    correct_samples = []\n",
    "    incorrect_samples = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            preds = output.argmax(dim=1)\n",
    "            \n",
    "            for i in range(len(data)):\n",
    "                if preds[i] == target[i] and len(correct_samples) < 3:\n",
    "                    correct_samples.append((data[i], target[i], preds[i]))\n",
    "                elif preds[i] != target[i] and len(incorrect_samples) < 3:\n",
    "                    incorrect_samples.append((data[i], target[i], preds[i]))\n",
    "                \n",
    "                if len(correct_samples) >= 3 and len(incorrect_samples) >= 3:\n",
    "                    break\n",
    "            \n",
    "            if len(correct_samples) >= 3 and len(incorrect_samples) >= 3:\n",
    "                break\n",
    "    \n",
    "    # Generate Grad-CAM visualizations\n",
    "    samples = correct_samples + incorrect_samples\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i, (img, true_label, pred_label) in enumerate(samples):\n",
    "        # Generate CAM\n",
    "        cam, _ = gradcam.generate(img, pred_label)\n",
    "        \n",
    "        # Convert to heatmap\n",
    "        heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
    "        heatmap = np.float32(heatmap) / 255\n",
    "        \n",
    "        # Denormalize original image\n",
    "        img_np = img.cpu().numpy().transpose((1, 2, 0))\n",
    "        img_np = img_np * std + mean  # Reverse normalization\n",
    "        img_np = np.clip(img_np, 0, 1)\n",
    "        \n",
    "        # Overlay heatmap on image\n",
    "        overlay = heatmap + np.float32(img_np)\n",
    "        overlay = overlay / np.max(overlay)\n",
    "        \n",
    "        # Plot\n",
    "        axes[i].imshow(overlay)\n",
    "        axes[i].set_title(f'True: {full_dataset.classes[true_label]}\\n'\n",
    "                         f'Pred: {full_dataset.classes[pred_label]}')\n",
    "        axes[i].axis('off')\n",
    "        \n",
    "        # Save individual images\n",
    "        plt.imsave(f'figures/gradcam_{i+1}.png', overlay)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('figures/gradcam_all.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Remove hooks\n",
    "    gradcam.remove_hooks()\n",
    "\n",
    "print(\"Generating Grad-CAM visualizations...\")\n",
    "apply_gradcam(model, test_loader, device)\n",
    "\n",
    "# Section 8: Save Models and Metrics\n",
    "# Already done during training and evaluation\n",
    "\n",
    "# Section 9: Display Summary of Results\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SUMMARY OF RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "print(f\"Macro F1: {macro_f1:.3f}\")\n",
    "print(f\"Weighted F1: {weighted_f1:.3f}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create a summary dataframe\n",
    "summary_df = pd.DataFrame({\n",
    "    'Metric': ['Test Accuracy', 'Macro F1', 'Weighted F1'],\n",
    "    'Value': [f\"{test_acc:.2f}%\", f\"{macro_f1:.3f}\", f\"{weighted_f1:.3f}\"]\n",
    "})\n",
    "summary_df.to_csv('results/summary.csv', index=False)\n",
    "\n",
    "print(\"All results and figures have been saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73718be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
